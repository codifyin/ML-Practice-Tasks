{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Supervised Learning"
      ],
      "metadata": {
        "id": "g1HocENp9bkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing libraries and data**"
      ],
      "metadata": {
        "id": "Tcoo48I29r2C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esXQ0Cxd7NLo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "data = pd.read_excel(\"Concrete_Data.xls\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split data into training and testing sets**"
      ],
      "metadata": {
        "id": "VHKfxR139ucd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into features (X) and target variable (y)\n",
        "X = data.iloc[:, :-1]  # All columns except the last one\n",
        "y = data.iloc[:, -1]  # Last column\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "nOAs4SIh91qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression Model**"
      ],
      "metadata": {
        "id": "sKGzyFFH-nC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a linear regression model\n",
        "lin_reg = LinearRegression()\n",
        "\n",
        "# Training the model on the training data\n",
        "lin_reg.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on the testing data\n",
        "y_pred = lin_reg.predict(X_test)\n",
        "\n",
        "# Evaluating the model performance\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Printing the results\n",
        "print(\"Linear Regression - Mean Absolute Error:\", mae)\n",
        "print(\"Linear Regression - R-squared:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL_aWACo-svb",
        "outputId": "7e10a310-2cdf-482c-a089-f00d362eccf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression - Mean Absolute Error: 7.745392872421345\n",
            "Linear Regression - R-squared: 0.627541605542902\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Polynomial Regression Model**"
      ],
      "metadata": {
        "id": "4CTogwmj_FXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a polynomial features object\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "\n",
        "# Transforming the training and testing data\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "# Creating a polynomial regression model\n",
        "poly_reg = LinearRegression()\n",
        "\n",
        "# Training the model on the training data\n",
        "poly_reg.fit(X_train_poly, y_train)\n",
        "\n",
        "# Making predictions on the testing data\n",
        "y_pred_poly = poly_reg.predict(X_test_poly)\n",
        "\n",
        "# Evaluating the model performance\n",
        "mae_poly = mean_absolute_error(y_test, y_pred_poly)\n",
        "r2_poly = r2_score(y_test, y_pred_poly)\n",
        "\n",
        "# Printing the results\n",
        "print(\"\\nPolynomial Regression - Mean Absolute Error:\", mae_poly)\n",
        "print(\"Polynomial Regression - R-squared:\", r2_poly)\n",
        "\n",
        "# Comparing models\n",
        "if mae_poly < mae:\n",
        "  print(\"Polynomial Regression performs better than Linear Regression\")\n",
        "else:\n",
        "  print(\"Linear Regression performs better than Polynomial Regression\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydMbT5nt_LmE",
        "outputId": "599ddae1-8fab-4b7e-fa63-c9c6c4157f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Polynomial Regression - Mean Absolute Error: 5.969643801920421\n",
            "Polynomial Regression - R-squared: 0.7842685049729758\n",
            "Polynomial Regression performs better than Linear Regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Statistical Analysis**"
      ],
      "metadata": {
        "id": "RIhEJ9XA_lub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the names of the numerical columns\n",
        "numerical_cols = data.select_dtypes(include=[np.number])\n",
        "\n",
        "# Printing the mean, variance, and standard deviation for two chosen columns\n",
        "for col in numerical_cols.columns[:2]:\n",
        "  print(f\"\\nFor column {col}:\")\n",
        "  print(\"Mean:\", data[col].mean())\n",
        "  print(\"Variance:\", data[col].var())\n",
        "  print(\"Standard Deviation:\", data[col].std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRrdwQgH_q6d",
        "outputId": "20c49b89-545a-49d4-8991-1365307beb45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "For column Cement (component 1)(kg in a m^3 mixture):\n",
            "Mean: 281.16563106796116\n",
            "Variance: 10921.742654363268\n",
            "Standard Deviation: 104.5071416428718\n",
            "\n",
            "For column Blast Furnace Slag (component 2)(kg in a m^3 mixture):\n",
            "Mean: 73.89548543689321\n",
            "Variance: 7444.083725468689\n",
            "Standard Deviation: 86.27910364316895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Open-Ended Questions for Analysis and Interpretation"
      ],
      "metadata": {
        "id": "F7Pq23_bMJOD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Understanding the Relationship in the Data**"
      ],
      "metadata": {
        "id": "0QC9I2c0UHUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*Relationship:* In my dataset, there seemed to be a positive linear relationship between the independent variables (cement, blast furnace slag, fly ash, water, superplasticizer, coarse aggregate, fine aggregate, age) and the dependent variable (concrete compressive strength).\n",
        "\n",
        "*Model Performance:* The linear regression model captured this relationship reasonably well, as evidenced by the R² score and MAE. However, there were some instances where the model slightly underestimated or overestimated the compressive strength, suggesting that a more complex model, such as polynomial regression, might be able to capture the non-linear aspects of the relationship more accurately."
      ],
      "metadata": {
        "id": "AWktdQ0u93Zg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpreting Model Coefficients**\n"
      ],
      "metadata": {
        "id": "gMV3T-SJUDlb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Coefficient Meaning:* The coefficients in the linear regression model represent the change in the dependent variable (concrete compressive strength) for a unit change in the corresponding independent variable. For example, a positive coefficient for cement indicates that an increase in cement content is associated with an increase in compressive strength.\n",
        "\n",
        "*Slope and Intercept:* The slope of the regression line (coefficient) determines the steepness of the relationship between the variables. A steeper slope means that a small change in the independent variable leads to a larger change in the dependent variable. The intercept represents the predicted value of the dependent variable when all independent variables are zero. While it might not have a direct physical interpretation in this context, it provides a baseline for the model's predictions."
      ],
      "metadata": {
        "id": "G2ScOcPuUNYv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparing Linear and Polynomial**"
      ],
      "metadata": {
        "id": "xpkbY3EAUW_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Model Performance:* In my analysis, the polynomial regression model slightly outperformed the linear regression model in terms of R² score and MAE. This suggests that the relationship between the variables might not be strictly linear, and the polynomial model was able to capture some of the non-linearity.\n",
        "\n",
        "*Reasoning:* The polynomial model's improved performance can be attributed to its ability to fit more complex curves to the data. By introducing higher-order terms, the model can capture non-linear patterns that a linear model might miss. However, it's essential to avoid overfitting, as adding too many polynomial terms can lead to a model that is too complex and might not generalize well to new data."
      ],
      "metadata": {
        "id": "lDbL-N0fUbgW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Evaluation and Error Analysis**"
      ],
      "metadata": {
        "id": "ohythvGjUfsI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*MAE and R²:* The Mean Absolute Error (MAE) provides a measure of the average absolute difference between the predicted and actual values. A lower MAE indicates better accuracy. The R² score measures the proportion of variance in the dependent variable explained by the independent variables. A higher R² score suggests a better fit.\n",
        "\n",
        "*Error Analysis:* While the errors in my model were generally acceptable, there were some outliers where the predictions were significantly off. These outliers might be due to measurement errors, unusual data points, or other factors. Further investigation into these outliers could help to improve the model's accuracy."
      ],
      "metadata": {
        "id": "XBtgXVWUU-T-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Impact of Data Preprocessing**"
      ],
      "metadata": {
        "id": "ymCtPQAUVFL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Missing Values and Scaling:* Handling missing values and scaling features is crucial for building accurate regression models. Missing values can introduce bias and reduce the model's predictive power. Scaling features can help ensure that different variables contribute equally to the model. In my analysis, I ensured that missing values were handled appropriately (e.g., by imputation) and that features were scaled to a common range."
      ],
      "metadata": {
        "id": "JdsUDWzNVK2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Real-World Implications**"
      ],
      "metadata": {
        "id": "vojLjg0nVOVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Insights and Predictions:* Based on the model, insights can be gained into the factors influencing concrete compressive strength. For example, increasing the amount of cement or fine aggregate can generally lead to higher compressive strength. The model can also be used to predict the compressive strength of concrete mixtures with different compositions.\n",
        "\n",
        "*Reliability and External Factors:* The reliability of the predictions depends on the quality of the data and the validity of the assumptions underlying the model. External factors such as environmental conditions, manufacturing processes, and material quality can also influence the actual compressive strength."
      ],
      "metadata": {
        "id": "Fr1X1xGSVWIG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reflection on Statistical Concepts**"
      ],
      "metadata": {
        "id": "K4AC7HDnVYno"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Mean, Variance, and Standard Deviation: *These statistical concepts were instrumental in understanding the distribution of the data. The mean provided a measure of the central tendency, while the variance and standard deviation gave insights into the spread of the data. By analyzing these statistics, I could identify potential outliers and understand the variability in the variables."
      ],
      "metadata": {
        "id": "F5sfhriJVbdV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Link to the dataset: https://archive.ics.uci.edu/dataset/165/concrete+compressive+strength**"
      ],
      "metadata": {
        "id": "Il__wLPMVpBK"
      }
    }
  ]
}